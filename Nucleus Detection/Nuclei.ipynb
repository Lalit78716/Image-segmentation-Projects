{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nuclei.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e94X6h2iiUra"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DZLgMp5rt2q"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from skimage.io import imread,imshow\n",
        "from skimage.transform import resize\n",
        "seed=12\n",
        "np.random.seed = seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJFTOkOeialU"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EopEA8Fienu"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c data-science-bowl-2018"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdQGJ6WNimmo"
      },
      "source": [
        "!mkdir stage1_test\n",
        "! unzip stage1_test.zip -d stage1_test\n",
        "!mkdir stage1_train\n",
        "! unzip stage1_train.zip -d stage1_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw7BT86ci1gK"
      },
      "source": [
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "TRAIN_PATH='/content/stage1_train/'\n",
        "TEST_PATH='/content/stage1_test/'\n",
        "\n",
        "#read all the id's from the training images\n",
        "train_ids = next(os.walk(TRAIN_PATH))[1] \n",
        "test_ids = next(os.walk(TEST_PATH))[1]  # [1] means list of subfolder\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re48iwiLRyyk"
      },
      "source": [
        "\n",
        "X_train = np.zeros((len(train_ids),IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS),dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_ids),IMG_HEIGHT,IMG_WIDTH,1),dtype=np.bool)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8r7SzoWrRuf"
      },
      "source": [
        "print(\"Resizing training images and masks \")\n",
        "for n,id_ in tqdm(enumerate(train_ids),total=len(train_ids)):\n",
        "  path = TRAIN_PATH + id_\n",
        "  # print(path)\n",
        "  # print(id_)\n",
        "  img = imread(path + '/images/' + id_ +'.png')[:,:,:IMG_CHANNELS]\n",
        "  # imshow(img)\n",
        "  # if n==1:\n",
        "  #   break\n",
        "  # print(img)\n",
        "  # print(img.shape)\n",
        "  img = resize(img,(IMG_HEIGHT,IMG_WIDTH),mode='constant',preserve_range=True)\n",
        "  X_train[n]=img # fill empty X_train values from img\n",
        "  # for mask\n",
        "  mask = np.zeros((IMG_HEIGHT,IMG_WIDTH,1),dtype=np.bool)\n",
        "  for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "    mask_ = imread(path + '/masks/' + mask_file)\n",
        "    mask_ = np.expand_dims(resize(mask_,(IMG_HEIGHT,IMG_WIDTH),mode='constant',preserve_range=True),axis=-1) # adding new axis\n",
        "    mask = np.maximum(mask_,mask)\n",
        "  Y_train[n] = mask\n",
        "#  this way we put all the mask of one image put together and make a one separate image\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcfs0p2829h4"
      },
      "source": [
        "X_test = np.zeros((len(test_ids),IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS),dtype=np.uint8)\n",
        "sizes_test = []\n",
        "print(\"Resizing test images \")\n",
        "for n,id_ in tqdm(enumerate(test_ids),total=len(test_ids)):\n",
        "  path = TEST_PATH + id_\n",
        "  img = imread(path + '/images/' + id_ +'.png')[:,:,:IMG_CHANNELS]\n",
        "  sizes_test.append([img.shape[0],img.shape[1]])\n",
        "  img = resize(img,(IMG_HEIGHT,IMG_WIDTH),mode='constant',preserve_range=True)\n",
        "  X_test[n]=img # fill empty X_test values from img\n",
        "  \n",
        "print(\"Done...!\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4QZ-k2HjZq0"
      },
      "source": [
        "image_x = random.randint(0,len(train_ids))\n",
        "imshow(X_train[image_x])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[image_x]))\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgVamR-tk6GD"
      },
      "source": [
        "# build the model\n",
        "inputs = tf.keras.layers.Input((IMG_WIDTH,IMG_HEIGHT,IMG_CHANNELS))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A_3ts_Tk8gG"
      },
      "source": [
        "# because keras layers Conv2D take floating value so we convert our input into floating value\n",
        "s=tf.keras.layers.Lambda(lambda x: x/255)(inputs)\n",
        "\n",
        "c1 = tf.keras.layers.Conv2D(16,(3,3),activation= 'relu',kernel_initializer= 'he_normal',padding='same')(s)\n",
        "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "c1 = tf.keras.layers.Conv2D(16,(3,3),activation= 'relu',kernel_initializer= 'he_normal',padding='same')(c1)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n",
        "\n",
        "\n",
        "c2 = tf.keras.layers.Conv2D(32,(3,3),activation= 'relu',kernel_initializer= 'he_normal',padding='same')(p1)\n",
        "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "c2 = tf.keras.layers.Conv2D(32,(3,3),activation= 'relu',kernel_initializer= 'he_normal',padding='same')(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n",
        "\n",
        "c3 = tf.keras.layers.Conv2D(64,(3,3),activation= 'relu',kernel_initializer= 'he_normal',padding='same')(p2)\n",
        "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "c3 = tf.keras.layers.Conv2D(64,(3,3),activation= 'relu',kernel_initializer= 'he_normal',padding='same')(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n",
        "\n",
        "c4 = tf.keras.layers.Conv2D(128,(3,3),activation= 'relu',kernel_initializer= 'he_normal',padding='same')(p3)\n",
        "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "c4 = tf.keras.layers.Conv2D(128,(3,3),activation= 'relu',kernel_initializer= 'he_normal',padding='same')(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n",
        "\n",
        "c5 = tf.keras.layers.Conv2D(256,(3,3),activation= 'relu',kernel_initializer= 'he_normal',padding='same')(p4)\n",
        "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "c5 = tf.keras.layers.Conv2D(256,(3,3),activation= 'relu',kernel_initializer= 'he_normal',padding='same')(c5)\n",
        "\n",
        "# upsampling\n",
        "\n",
        "u6 = tf.keras.layers.Conv2DTranspose(128,(2,2),strides=(2,2),padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6,c4])\n",
        "c6 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u6)\n",
        "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "c6 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c6)\n",
        "\n",
        "u7 = tf.keras.layers.Conv2DTranspose(64,(2,2),strides=(2,2),padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7,c3])\n",
        "c7 = tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u7)\n",
        "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "c7 = tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c7)\n",
        "\n",
        "u8 = tf.keras.layers.Conv2DTranspose(32,(2,2),strides=(2,2),padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8,c2])\n",
        "c8 = tf.keras.layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u8)\n",
        "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "c8 = tf.keras.layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c8)\n",
        "\n",
        "u9 = tf.keras.layers.Conv2DTranspose(16,(2,2),strides=(2,2),padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9,c1],axis=3)\n",
        "c9 = tf.keras.layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u9)\n",
        "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "c9 = tf.keras.layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c9)\n",
        "\n",
        "outputs = tf.keras.layers.Conv2D(1,(1,1),activation = 'sigmoid')(c9)\n",
        "\n",
        "model = tf.keras.Model(inputs=[inputs],outputs=[outputs])\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "# model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "# model.compile(optimizer='RMSprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "#  becuase it is binary classification either it is a cell or not a cell so we use binary crossentropy\n",
        "\n",
        "\n",
        "\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW9bD0EUlAHZ"
      },
      "source": [
        "################################################\n",
        "#model check point\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.h5',verbose=1,save_best_only=True)\n",
        "callbacks=[\n",
        "           tf.keras.callbacks.EarlyStopping(patience=2,monitor='val_loss'),\n",
        "           tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
        "           ]\n",
        "\n",
        "history = model.fit(X_train,Y_train,validation_split=0.1,batch_size=16,epochs=25,callbacks=callbacks)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBMdJoOMlHdE"
      },
      "source": [
        "#############################################\n",
        "idx = random.randint(0,len(X_train))\n",
        "\n",
        "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)],verbose=1)\n",
        "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):],verbose=1)\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
        "\n",
        "# sanity check on some random training samples\n",
        "ix = random.randint(0,len(preds_train_t))\n",
        "imshow(X_train[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_train_t[ix]))\n",
        "plt.show()\n",
        "\n",
        "# sanity check on some random validation samples\n",
        "ix = random.randint(0,len(preds_val_t))\n",
        "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_val_t[ix]))\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfmdpsAxhmIv"
      },
      "source": [
        "ix = random.randint(0,len(preds_test_t))\n",
        "imshow(X_test[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_test_t[ix]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "656f8ng6PvdP"
      },
      "source": [
        "# !tensorboard --logdir=logs/ --host localhost --port 5000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE4A9MR6JvZp"
      },
      "source": [
        "acc =history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1,len(acc)+1)\n",
        "\n",
        "plt.plot(epochs,acc,'b',label='Training Accuracy')\n",
        "plt.plot(epochs,val_acc,'r',label='Validation Accuracy')\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training and Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.savefig(\"T_V_accuracy_rms.png\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs,loss,'b',label='Training Loss')\n",
        "plt.plot(epochs,val_loss,'r',label='Validation Loss')\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.savefig(\"T_V_loass_rms.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWy_Cw-V8oeG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEdUw-S5cBzL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpdeTPqjiyoh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}